{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application part (You need a trained model loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def choice (score):\n",
    "    score_tmp = 0\n",
    "    ind = 0\n",
    "    for i in range(len(score)):\n",
    "        if score[i] > score_tmp :\n",
    "            score_tmp = score[i]\n",
    "            ind = i\n",
    "    return ind,score_tmp\n",
    "\n",
    "def second_choice (score,max_tmp):\n",
    "    score_tmp = 0\n",
    "    for i in range(len(score)):\n",
    "        if (score[i] > score_tmp) and (score[i] != max_tmp):\n",
    "            score_tmp = score[i]\n",
    "            ind = i\n",
    "    return ind\n",
    "\n",
    "\n",
    "name={0:\"thumb_up\",1:\"thumb_down\",2:\"fist_1\",\n",
    "      3:\"fist_2\",4:\"fist_3\",5:\"peace\",6:\"rock\",7:\"nice\",\n",
    "      8:\"finger_up\" ,9:\"finger_up_2\",\n",
    "      10:\"palm\",11:\"spok\",12:\"call\"}\n",
    "\n",
    "image={}\n",
    "images_path = \"variables/emojis/\"#Path where the images of the emojis are stored (.png)\n",
    "for n in name.values() : \n",
    "    image[n]= cv2.imread(images_path+n+\".png\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "save = []\n",
    "cap.set(3,200)\n",
    "cap.set(4,200)\n",
    "max_tmp = 0\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    # Our operations on the frame come here\n",
    "\n",
    "    cv2.rectangle(frame,(0,0),(141,111),color=3)\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    x_tmp = frame[:110,:140,:]\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "    x_tmp = x_tmp.reshape(1, 110, 140,3)\n",
    "    pred = model_final.predict(x_tmp)\n",
    "    name_first = name[choix(pred[0])[0]]\n",
    "    max_tmp = choice(pred[0])[1]\n",
    "    name_second = name[second_choice(pred[0],max_tmp)]\n",
    "\n",
    "    cv2.imshow('First choice',image[name_first])\n",
    "    cv2.imshow('Second choice',image[name_second])\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This part is used to capture the different images needed for the dataset\n",
    "Press \"c\" to capture one image and press \"q\" to quit the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "save = []\n",
    "cap.set(3,200)\n",
    "cap.set(4,200)\n",
    "max_tmp = 0\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    cv2.rectangle(frame,(0,0),(141,111),color=3)\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    x_tmp = frame[:110,:140,:]\n",
    "\n",
    "    if cv2.waitKey(1) == ord('c'):\n",
    "        save.append(x_tmp)\n",
    "        print(len(save))\n",
    "        \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    #i+=1\n",
    "    \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"call\" # The name you want to give to your captured emoji\n",
    "path = \"datasets/emojis/ # The path where you want to save the dataset\n",
    "i =100\n",
    "for e in save : \n",
    "    cv2.imwrite( +name+\"/\"+ str(i)+\".jpg\", e );\n",
    "    i+=1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import Augmentor\n",
    "\n",
    "# An array containing all the names you've given to your emojis\n",
    "name=[\"thumb_up\",\"thumb_down\",\"fist_1\",\"fist_2\",\"fist_3\",\"crossed_fingers\",\"peace\",\"rock\",\"nice\",\"finger_up\",\"finger_up_2\",\"palm\",\"spok\",\"call\"]\n",
    "dataset_path = 'datasets/emojis_2/'\n",
    "for name in name :\n",
    "    path = dataset_path +name   \n",
    "    p = Augmentor.Pipeline(source_directory=path,output_directory=\"\")\n",
    "    p.random_distortion(probability=1, grid_width=4, grid_height=4, magnitude=8)\n",
    "    p.flip_left_right(probability=0.5)\n",
    "    p.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening of the data and splitting in test and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob   \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "i = 0\n",
    "img_width = 110\n",
    "img_height = 140\n",
    "name=[\"thumb_up\",\"thumb_down\",\"fist_1\",\"fist_2\",\"fist_3\",\"peace\",\"rock\",\"nice\",\"finger_up\" ,\"finger_up_2\",\"palm\",\"spok\",\"call\"]\n",
    "\n",
    "for name in name :\n",
    "    path = 'datasets/emojis_2/'+name+'/*.jpg'   \n",
    "    files=glob.glob(path)   \n",
    "    for file in files:  \n",
    "        x.append(cv2.imread(file))\n",
    "        y.append(i)\n",
    "    i+=1     \n",
    "    \n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)    \n",
    "x = np.array(x)    \n",
    "x = x.reshape(x.shape[0], img_width, img_height,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.1,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the model and learning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "img_width, img_height = 110, 140\n",
    "batch_size = 50\n",
    "epochs = 7\n",
    "\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(13, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "#,callbacks=[LearningRateScheduler(schedule, verbose=0)]\n",
    "hist_transfer = model_final.fit(x_train, y_train, epochs=epochs,batch_size =batch_size,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue training of the model without having to create again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "hist_transfer = model_final.fit(x_train, y_train, epochs=3,batch_size =50,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model_final.predict(x_test)\n",
    "y_pred = y_pred.argmax(axis=-1)\n",
    "y_true = np.argmax( y_test ,axis=1)\n",
    "\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "print(model_final.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and opening of the model on the disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,name,path):\n",
    "    model_json = model.to_json()\n",
    "    with open(path+name+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "        model.save_weights(path+name+\".h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "        \n",
    "def load_model(name,path):\n",
    "    from keras.models import model_from_json\n",
    "    # load json and create model\n",
    "    json_file = open(path+name+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(path+name+\".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_final,\"Transfer_final\",\"models/emojis/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model_final = load_model(\"Transfer_final\",\"models/emojis/\")\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
